# -*- coding: utf-8 -*-
"""udacity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CRhIi-xGG9vlRyg1VMJeUhF4PghT90QW
"""

# importing necessary libs:
import pandas as pd
import string
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from nltk.stem.porter import PorterStemmer

# uploading kaggle daatset for udacity courses:

from google.colab import files
files.upload()

!mkdir -p ~/.dataset_task0
!cp kaggle.json ~/.dataset_task0/

!chmod 600 ~/.dataset_task0/kaggle.json

!pip install kaggle

!kaggle datasets download -d khusheekapoor/udacity-courses-dataset-2021

!unzip udacity-courses-dataset-2021.zip

# exploring the dataset:
df_1 = pd.read_csv('Udacity.csv')
df_1.head()
df_1.info()

df = df_1[['Name', 'Difficulty Level', 'About']]

# text preprocessing:
nltk.download('punkt')
nltk.download('stopwords')

def preprocess_text(text):
    if isinstance(text, str):
        text = text.lower()
        text = text.strip()
        text = text.translate(str.maketrans('', '', string.punctuation))
        tokens = nltk.word_tokenize(text)
        stop_words = set(stopwords.words('english'))
        tokens = [word for word in tokens if word not in stop_words]
        text = ' '.join(tokens)
    return text

columns_to_preprocess = ['Name', 'Difficulty Level', 'About']
for column in columns_to_preprocess:
    if column in df.columns:
        df[column] = df[column].apply(preprocess_text)

df['new_col'] = df['Name'] + ' ' + df['Difficulty Level'] + ' ' + df['About']

ps = PorterStemmer()

def stem(text):
    if not isinstance(text, str):
        return ""
    return " ".join([ps.stem(word) for word in text.split()])

df['new_col'] = df['new_col'].fillna('')

df['new_col'] = df['new_col'].apply(stem)

cv = CountVectorizer(max_features=5000, stop_words='english')
vectors = cv.fit_transform(df['new_col']).toarray()

similarity = cosine_similarity(vectors)

def recommend(course):
    try:
        preprocessed_course = preprocess_text(course)
        stemmed_course = stem(preprocessed_course)

        matches = df[df['new_col'].str.contains(stemmed_course, regex=False, na=False)]
        if not matches.empty:
            course_index = matches.index[0]
            distances = similarity[course_index]
            course_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:7]

            print("Recommended courses:")
            for i in course_list:
                print(df_1.iloc[i[0]]['Name'])
        else:
            print("Course not found. Please check the course title.")

    except IndexError:
        print("Course not found. Please check the course title.")

recommend('Machine Learning')

# exporting the model:
import pickle

with open('udacity_vectorizer.pkl', 'wb') as file:
    pickle.dump(cv, file)

with open('udacity_similarity.pkl', 'wb') as file:
    pickle.dump(similarity, file)

